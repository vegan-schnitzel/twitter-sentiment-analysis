{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "import pandas as pd\r\n",
    "\r\n",
    "# natural language processing\r\n",
    "import spacy\r\n",
    "\r\n",
    "# load spacy's english language model \r\n",
    "nlp = spacy.load('en_core_web_sm')\r\n",
    "\r\n",
    "# testing...\r\n",
    "test = \"Hello, FUCKING world! What the fuck! I am fucked...\" \r\n",
    "tweet = \"IM SO FUCKING PISSED!!! I HATE YOU TRUMP, I WANTED TO START WW3\"\r\n",
    "\r\n",
    "doc = nlp(test)\r\n",
    "\r\n",
    "text = []\r\n",
    "lemma = []\r\n",
    "pos = []\r\n",
    "tag = []\r\n",
    "explanation = []\r\n",
    "\r\n",
    "for token in doc:\r\n",
    "    text.append(token.text)\r\n",
    "    lemma.append(token.lemma_)\r\n",
    "    pos.append(token.pos_)\r\n",
    "    tag.append(token.tag_)\r\n",
    "    explanation.append(spacy.explain(token.tag_))\r\n",
    "\r\n",
    "d = {'text': text, 'lemma': lemma, 'UPOS part-of-speech tag': pos, 'detailed tag': tag, 'explanation of tag': explanation}\r\n",
    "df = pd.DataFrame(data=d)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>UPOS part-of-speech tag</th>\n",
       "      <th>detailed tag</th>\n",
       "      <th>explanation of tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>hello</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>UH</td>\n",
       "      <td>interjection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punctuation mark, comma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUCKING</td>\n",
       "      <td>fucking</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>WP</td>\n",
       "      <td>wh-pronoun, personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fuck</td>\n",
       "      <td>fuck</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>adjective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>pronoun, personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>am</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>verb, non-3rd person singular present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fucked</td>\n",
       "      <td>fuck</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>verb, past participle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>:</td>\n",
       "      <td>punctuation mark, colon or ellipsis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text    lemma UPOS part-of-speech tag detailed tag  \\\n",
       "0     Hello    hello                    INTJ           UH   \n",
       "1         ,        ,                   PUNCT            ,   \n",
       "2   FUCKING  fucking                    NOUN           NN   \n",
       "3     world    world                    NOUN           NN   \n",
       "4         !        !                   PUNCT            .   \n",
       "5      What     what                    PRON           WP   \n",
       "6       the      the                     DET           DT   \n",
       "7      fuck     fuck                     ADJ           JJ   \n",
       "8         !        !                   PUNCT            .   \n",
       "9         I   -PRON-                    PRON          PRP   \n",
       "10       am       be                     AUX          VBP   \n",
       "11   fucked     fuck                    VERB          VBN   \n",
       "12      ...      ...                   PUNCT            :   \n",
       "\n",
       "                       explanation of tag  \n",
       "0                            interjection  \n",
       "1                 punctuation mark, comma  \n",
       "2                  noun, singular or mass  \n",
       "3                  noun, singular or mass  \n",
       "4       punctuation mark, sentence closer  \n",
       "5                    wh-pronoun, personal  \n",
       "6                              determiner  \n",
       "7                               adjective  \n",
       "8       punctuation mark, sentence closer  \n",
       "9                       pronoun, personal  \n",
       "10  verb, non-3rd person singular present  \n",
       "11                  verb, past participle  \n",
       "12    punctuation mark, colon or ellipsis  "
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basically, spaCy's trained model recognises **FUCKING** or **PISSED** as nouns, not verbs, and forms the lemma in an unfavourable way. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "!python -m spacy info"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m\n",
      "============================== Info about spaCy ==============================\u001b[0m\n",
      "\n",
      "spaCy version    2.3.5                         \n",
      "Location         C:\\Users\\hotte\\miniconda3\\envs\\machinelearning\\lib\\site-packages\\spacy\n",
      "Platform         Windows-10-10.0.19041-SP0     \n",
      "Python version   3.7.10                        \n",
      "Models                                         \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I'm running v2 of spaCy, which still forms lemmas automatically as part of the trained pipeline, see: [https://spacy.io/usage/linguistic-features#lemmatization]().\r\n",
    "\r\n",
    "***\r\n",
    "\r\n",
    "**UPDATE**: Actually, spaCy v2 is deprecated and a lot of stuff in the v3 documentation doesn't apply, just found the old website though: [https://v2.spacy.io/](). For example, in v2 pipelines don't have an additional _lemmatizer_ component, consequently, all other pipeline components can be disabled without altering the lemmatization result.\r\n",
    "\r\n",
    "In v3, it should be possible to add the *lemmatizer* component to the nlp pipeline and investigate its two modi operandi: 'rule' and 'lookup'. The first referring to a lookup table without reference to the token's part-of-speech or context, and the latter being rule-based. For bodys of text with limited content and therefore with limited context (i.e., tweets), the 'lookup' option should provide more consistent lemmas, as indicated here: [https://github.com/explosion/spaCy/discussions/9235]()."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# load spacy's english language model without additional components\r\n",
    "tag = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner'])\r\n",
    "\r\n",
    "doc = tag(test)\r\n",
    "\r\n",
    "text = []\r\n",
    "lemma = []\r\n",
    "pos = []\r\n",
    "tag = []\r\n",
    "explanation = []\r\n",
    "\r\n",
    "for token in doc:\r\n",
    "    text.append(token.text)\r\n",
    "    lemma.append(token.lemma_)\r\n",
    "    pos.append(token.pos_)\r\n",
    "    tag.append(token.tag_)\r\n",
    "    explanation.append(spacy.explain(token.tag_))\r\n",
    "\r\n",
    "d = {'text': text, 'lemma': lemma, 'UPOS part-of-speech tag': pos, 'detailed tag': tag, 'explanation of tag': explanation}\r\n",
    "df = pd.DataFrame(data=d)\r\n",
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>UPOS part-of-speech tag</th>\n",
       "      <th>detailed tag</th>\n",
       "      <th>explanation of tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Hello</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FUCKING</td>\n",
       "      <td>FUCKING</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What</td>\n",
       "      <td>What</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fuck</td>\n",
       "      <td>fuck</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>am</td>\n",
       "      <td>be</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fucked</td>\n",
       "      <td>fuck</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text    lemma UPOS part-of-speech tag detailed tag explanation of tag\n",
       "0     Hello    Hello                                                    None\n",
       "1         ,        ,                                                    None\n",
       "2   FUCKING  FUCKING                                                    None\n",
       "3     world    world                                                    None\n",
       "4         !        !                                                    None\n",
       "5      What     What                                                    None\n",
       "6       the      the                                                    None\n",
       "7      fuck     fuck                                                    None\n",
       "8         !        !                                                    None\n",
       "9         I        I                                                    None\n",
       "10       am       be                                                    None\n",
       "11   fucked     fuck                                                    None\n",
       "12      ...      ...                                                    None"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('machinelearning': conda)"
  },
  "interpreter": {
   "hash": "39461eb1ccb5b97dce938e2e23dbf7233ea65aeea4aeb9a31811f79a807c05f2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}